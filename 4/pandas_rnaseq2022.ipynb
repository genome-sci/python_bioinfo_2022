{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNA-seqカウントデータの前処理\n",
    "本講義では、pandasを用いてRNA-seqカウントデータの処理を行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNA-seqとは\n",
    "RNA-seqとは, mRNAやmiRNAの配列をシーケンスして、発現量の定量や新規転写産物の同定を行う手法です。<br>\n",
    "シーケンスで得られたデータ（リード）は, 以下のようなステップで解析します。<br>\n",
    "1. リードのトリミング\n",
    "2. ゲノム配列へのマッピング\n",
    "3. マッピングされたリード数を数える\n",
    "4. サンプル毎の総リード数の違いや、遺伝子配列長の違いを補正（正規化） \n",
    "5. 遺伝子毎の発現量を同定、比較\n",
    "\n",
    "本講義では上記ステップのうち4以降を扱います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  本講義で用いるRNA-seqデータについて\n",
    "本講義では, 疾患モデルマウスのRNA-seqデータセット（GSE190806）を使用します。<br>\n",
    "\n",
    "Impaired KDM2B-mediated PRC1 recruitment to chromatin causes defective neural stem cell self-renewal and ASD/ID-like behaviors [RNA-Seq]<br>\n",
    "https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE190806<br>\n",
    "https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE190807<br>\n",
    "（GSE190806とGSE190807のRNA-seqは同じSRAアクセッション）\n",
    "\n",
    "このRNA-seqデータはINSDCのSRAデータベースにアクセッション番号 SRR17223720-SRR17223725 としてアーカイブされています。<br>\n",
    "SRR17223720-SRR17223722 Neural progenitor cells(C57BL/6J由来), wild-type<br>\n",
    "SRR17223723-SRR17223725 Neural progenitor cells(C57BL/6J由来), Kdm2b one allele mutant<br>\n",
    "このほか, サンプルの詳細は以下の論文を参照してください。<br>\n",
    "\n",
    "Impaired KDM2B-mediated PRC1 recruitment to chromatin causes defective neural stem cell self- renewal and ASD/ID-like behaviors<br>\n",
    "DOI:https://doi.org/10.1016/j.isci.2022.103742\n",
    "\n",
    "\n",
    "アーカイブされたデータをダウンロードして遺伝子ごとのカウントデータにするまでの手順と, 使用したソフトウェアは以下の通りです。<br>\n",
    "\n",
    "1. シークエンスデータの取得 fasterq-dump v3.0.0 ( https://github.com/ncbi/sra-tools )\n",
    "2. リファレンス:GRCm39のcDNA配列（ Mus_musculus.GRCm39.cdna.all.fa, http://asia.ensembl.org/Mus_musculus/Info/Index )\n",
    "3. リードの前処理 (リードトリミング、クオリティフィルタリングなど) fastp v0.23.2 ( https://github.com/OpenGene/fastp )\n",
    "4. 転写産物の定量 kallisto v0.48.0 ( https://github.com/pachterlab/kallisto )\n",
    "\n",
    "これらの処理の詳しい内容については本講習会では扱いません。何卒ご了承ください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 本講義で行うRNA-seqデータの処理\n",
    "\n",
    "- データの読み込み\n",
    "- カウントデータの正規化（ RPM/FPM, FPKM, TPM)\n",
    "- サンプル間のクラスタリング　\n",
    "- 遺伝子のアノテーション( transcript_idとgene_idの対応、gene_idに対応したdescriptionの付与 )\n",
    "- 発現量比 ( fold-change )の計算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.データファイルの読み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 準備\n",
    "pandas を pd としてインポートします。同様に numpy を np としてインポートします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandasのimport\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SRR17223720-SRR17223725 のカウントデータをまとめたファイル ( counts_kalisto.tsv ) のパスを指定します。<br>\n",
    "同様に、アノテーションデータとしてtranscript_idとgene_idを紐づけたファイル( transcript_name.tsv )、<br>\n",
    "gene id と description を紐づけたファイル ( description.tsv ) のパスも指定します。<br>\n",
    "アノテーションデータはGRCm39のGFFファイル( Mus_musculus.GRCm39.108.gff3 ) から必要な情報を抽出して作成しました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_file = 'data/counts_kallisto.tsv'\n",
    "transcript_name_file = 'data/transcript_name.tsv'\n",
    "description_file = 'data/description.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### カウントデータファイルについて<br>\n",
    "counts_kallisto.tsvを開くと以下のようになっています。<br>\n",
    "```\n",
    "target_id\teff_length\tSRR17223720\tSRR17223721\tSRR17223722\tSRR17223723\tSRR17223724\tSRR17223725\n",
    "ENSMUST00000178537.2\t6.74193\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\n",
    "ENSMUST00000178862.2\t7.65825\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\n",
    "ENSMUST00000196221.2\t5.34639\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\n",
    "ENSMUST00000179664.2\t6.27959\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\n",
    "ENSMUST00000177564.2\t8.56364\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\n",
    "... 以下省略\n",
    "```\n",
    "1行目は列タイトルを表すヘッダー行です。<br>\n",
    "2行目以降からがデータ行です。一番左の列が遺伝子idになっているのでこれをインデックスに用います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pd.read_table()` メソッドの`index_col`オプションを指定して読み込みます。<br>\n",
    "\n",
    "- index_col...インデックスとして用いる列を数字で指定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table(count_file, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pd.read_table(path/to/file)` のかわりに`pd.read_csv(path/to/file,sep='\\t') `を用いることもできます。<br>\n",
    "`sep='\\t'`は`delimiter='\\t'` も使えます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### データの概観\n",
    "データを概観してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head()で列名とインデックスが正しく読み込まれているかを確認します\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'eff_length'列だけ確認\n",
    "df.eff_length.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "カウントデータファイルの行数と列数を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ件数を確認\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 列名を変更する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 列名を変更するための対応表\n",
    "names = {'SRR17223720': 'wt_1',\n",
    "         'SRR17223721': 'wt_2',\n",
    "         'SRR17223722': 'wt_3',\n",
    "         'SRR17223723': 'mutant_1',\n",
    "         'SRR17223724': 'mutant_2',\n",
    "         'SRR17223725': 'mutant_3'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`rename()` を `axis=1` を適用して使い、列名を変更します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(mapper=names, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`rename()` を使わなくても、既存の列を別名でコピーした後で元の列を削除、という方法でも可能です。\n",
    "```\n",
    "df['wt_1'] = df['SRR17223720']\n",
    "del df['SRR17223720']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "カウントデータ部分のみを切り出し"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count = df[['wt_1','wt_2','wt_3','mutant_1','mutant_2','mutant_3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# スライスで指定する場合　\n",
    "df.iloc[:, 1:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ファイルの保存\n",
    "保存用に`output/`フォルダを用意し, estimate_countのみのデータを`count_raw.tsv`として保存します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate_countのみのデータの保存\n",
    "df_count.to_csv('output/count_raw.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "シェルコマンド head を使って確認してみます。<br>\n",
    "`%%bash`でJupyter notebookのセル内でbashコマンドを実行させることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "head output/count_raw.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. カウントデータの正規化\n",
    "#### Step1. リード数で正規化 (RPM/FPM)\n",
    "\n",
    "100万リードあたりのカウント数に揃えます。<br>\n",
    "RPM = reads per million, FPM = fragments per million<br>\n",
    "ほぼ同じ意味で用いられているので, 本講義では「FPM」を使います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "カウントデータをいったん別のデータフレームとしてコピーしておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = df_count.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.iloc[6085:6090,] # head()だと0.0ばかりになる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# リード数の合計　sum()を使って計算\n",
    "sum_count = df_tmp.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100万リードあたりに揃える\n",
    "df_tmp = 10**6 * df_tmp / sum_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.iloc[6085:6090,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "リード数の合計が100万に揃っていることを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "`normalize_per_million_reads()` として関数化しておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_per_million_reads(df):\n",
    "    sum_count = df.sum()\n",
    "    return 10**6 * df / sum_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "カウントデータに適用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_fpm = normalize_per_million_reads(df_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_fpm.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "FPM正規化を行った結果を `count_fpm.tsv` として保存します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_fpm.to_csv('output/count_fpm.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step2. 遺伝子長による正規化 (RPKM/FPKM)\n",
    "上で求めたFPMをさらに遺伝子長で割ってFPKMを求めます。<br>\n",
    "FPKM = fragments per kilobase of exon per million reads mapped <br>\n",
    "今回用いたsingle-endの場合、RPKM = reads per kilobase of exon per million reads mapped と呼ばれますが, <br>\n",
    "FPKM/RPKMはほぼ同じ意味で用いられています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各遺伝子の長さを抽出しておきます。<br>\n",
    "kallistoでは実際の配列長（abundance.tsvの`length`列）ではなく、`eff_length`列でTPMを計算しているので、<br>\n",
    "本講義でも`eff_length`列の値を用います。<br>\n",
    "参考　次世代シーケンサーデータの解析手法 第 15 回 RNA-seq 解析（その3）<br>\n",
    "DOI: https://doi.org/10.4109/jslab.31.25\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_length = df['eff_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下のように書くとうまくいきません。（縦方向にブロードキャストされてしまうため）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tmp / gene_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一列ずつ計算することは可能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tmp[\"batch_1\"] / gene_length * 10**3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### for ループを使う方法\n",
    "データフレームをforループで回すと、列名が取得できるのでそれを利用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テスト用にDataFrameをコピーしてから\n",
    "df_tmp = df_count_fpm.copy()\n",
    "\n",
    "for col_name in df_tmp:\n",
    "    df_tmp[col_name] = df_tmp[col_name] / gene_length * 10**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.iloc[6085:6090,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`iteritems()` を利用する方法もあります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = df_count_fpm.copy()\n",
    "\n",
    "for col_name, col in df_tmp.iteritems():\n",
    "    df_tmp[col_name] = col / gene_length * 10**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.iloc[6085:6090,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### データフレームを転置してから計算する方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テスト用にFPMをコピー\n",
    "df_tmp = df_count_fpm.copy()\n",
    "\n",
    "# df_tmpを転置してFPMを遺伝子長で割り, 1000をかける\n",
    "df_tmp = df_tmp.T / gene_length * 10**3\n",
    "\n",
    "# 戻す（もう一度転置する）\n",
    "df_tmp = df_tmp.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.iloc[6085:6090,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### applyを使い各列に関数を適用する方法\n",
    "`divide_by_length()`という関数を作り、`apply()` で適用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 列を入力とし、各要素を遺伝子長で割る処理を行う関数を定義\n",
    "def divide_by_length(S):\n",
    "    return S / gene_length * 10**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テスト用にFPMをコピー\n",
    "df_tmp = df_count_fpm.copy()\n",
    "\n",
    "# applyでdivide_by_length()関数を適用して先頭だけ確認\n",
    "df_tmp.apply(divide_by_length).iloc[6085:6090,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas.DataFrame`メソッドの `divide()` を使用する方法もあります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テスト用にFPMをコピー\n",
    "df_tmp = df_count_fpm.copy()\n",
    "\n",
    "df_tmp = df_tmp.divide(gene_length, axis='index') * 10**3\n",
    "df_tmp.iloc[6085:6090,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "データフレームを転置させて計算する方法を `normalize_per_kilobase()` として関数化しておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_per_kilobase(df, gene_length):\n",
    "    df_tmp = df.copy()\n",
    "    df_tmp = (df.T * 10**3 / gene_length).T \n",
    "    return df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_fpkm = normalize_per_kilobase(df_count_fpm, gene_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_fpkm.iloc[6085:6090,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存する\n",
    "df_count_fpkm.to_csv('output/count_fpkm.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step3. TPM 正規化\n",
    "TPM = transcripts per million <br> \n",
    "TPM の説明については以下のページが詳しいです。 https://bi.biopapyrus.jp/ <br> \n",
    "\n",
    "FPKM/RPKM のときとは逆に、長さ1,000bpあたりのリード数を求めてから、総リード数を100万に揃えます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テスト用にカウントデータをコピー\n",
    "df_tmp = df_count.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = normalize_per_kilobase(df_tmp, gene_length) #長さ1,000bpあたりのリード数\n",
    "df_tmp = normalize_per_million_reads(df_tmp) #総リード数を100万に揃える"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.iloc[6085:6090,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RPKM/FPKMと違い、合計が100万となっています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "`normalize_tpm()` として関数化しておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_tpm(df, gene_length):\n",
    "    df_tmp = df.copy()\n",
    "    df_tmp = normalize_per_kilobase(df_tmp, gene_length)\n",
    "    df_tmp = normalize_per_million_reads(df_tmp)\n",
    "    return df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_tpm = normalize_tpm(df_count, gene_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_tpm.sum() #  確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存\n",
    "df_count_tpm.to_csv('output/count_tpm.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 参考）numpyを使った高速バージョンとの比較 <br>\n",
    "\n",
    "`%%timeit`はコードの時間計測を何回か試し, その中で最速の時間と平均値を返すマジックコマンドです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# pandasで実装したもの\n",
    "normalize_tpm(df_count, gene_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valuesによりnumpy.ndarrayとして数値データを抽出\n",
    "counts = df_count.values\n",
    "length =gene_length.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# numpyで計算\n",
    "# 長さで正規化。行方向へbroadcastを行うため、reshapeしておく必要がある\n",
    "counts_tmp = counts / length.reshape(-1, 1) * 1000\n",
    "# カウント数の各列の合計を求めておく\n",
    "sum_count = counts_tmp.sum(axis=0)\n",
    "# 100万カウントに揃える\n",
    "tpm = counts_tmp / sum_count * 1000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3. TPM正規化したデータのクラスタリング\n",
    "matplotlib と scipy の必要モジュールをインポートします。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 転置\n",
    "tpm_t = df_count_tpm.T\n",
    "tpm_t.iloc[:,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# クラスタリング\n",
    "linkage_result = linkage(tpm_t, method='average', metric='correlation')\n",
    "\n",
    "# 結果の可視化\n",
    "plt.figure(num=None, figsize = (12,4), facecolor='w', edgecolor='k')\n",
    "dendrogram(linkage_result,labels = list(tpm_t.index) )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考：PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(tpm_t)\n",
    "\n",
    "# データを主成分空間に写像\n",
    "pca_row = pca.transform(tpm_t)\n",
    "\n",
    "# 寄与率を求める\n",
    "pca_col = [\"PC{}\".format(x + 1) for x in range(len(tpm_t.index))]\n",
    "df_con_ratio = pd.DataFrame([pca.explained_variance_ratio_], columns = pca_col)\n",
    "print(df_con_ratio.head())\n",
    "\n",
    "# PC1とPC2でplot\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.scatter(pca_row[:, 0], pca_row[:, 1], alpha=0.8, c=(1,1,1,2,2,2))\n",
    "plt.grid()\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "annotations = tpm_t.index\n",
    "for i, label in enumerate(annotations):\n",
    "    plt.annotate(label, (pca_row[i, 0], pca_row[i, 1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 遺伝子アノテーションをつける"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step1. アノテーションファイルを読み込む\n",
    "\n",
    "transcript_name.tsvを開くと以下のようになっています。<br>\n",
    "\n",
    "```\n",
    "ENSMUST00000070533.5\tXkr4-201\tENSMUSG00000051951\n",
    "ENSMUST00000208660.2\tRp1-202\tENSMUSG00000025900\n",
    "ENSMUST00000027032.6\tRp1-201\tENSMUSG00000025900\n",
    "ENSMUST00000027035.10\tSox17-201\tENSMUSG00000025902\n",
    "ENSMUST00000195555.2\tSox17-208\tENSMUSG00000025902\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame名を `transcript_name` として、 <br>\n",
    "ヘッダー（列名）は `names=['transcript_id', 'transcript_name', 'gene_id']`として読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_name = pd.read_table(transcript_name_file, names=['transcript_id', 'transcript_name', 'gene_id'])\n",
    "print(transcript_name.shape)\n",
    "transcript_name.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "description.tsvを開くと以下のようになっています。<br>\n",
    "\n",
    "```\n",
    "ENSMUSG00000102693\t4933401J01Rik\tRIKEN cDNA 4933401J01 gene [Source:MGI Symbol%3BAcc:MGI:1918292]\n",
    "ENSMUSG00000051951\tXkr4\tX-linked Kx blood group related 4 [Source:MGI Symbol%3BAcc:MGI:3528744]\n",
    "ENSMUSG00000103377\tGm37180\tpredicted gene%2C 37180 [Source:MGI Symbol%3BAcc:MGI:5610408]\n",
    "ENSMUSG00000104017\tGm37363\tpredicted gene%2C 37363 [Source:MGI Symbol%3BAcc:MGI:5610591]\n",
    "ENSMUSG00000103025\tGm37686\tpredicted gene%2C 37686 [Source:MGI Symbol%3BAcc:MGI:5610914]\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame名を `gene_desctiption` として、<br>\n",
    "ヘッダー（列名）は `names=['gene_id', 'gene_name','description']`として読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_description = pd.read_table(description_file, names=['gene_id', 'gene_name','description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gene_description.shape)\n",
    "gene_description.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step2. 2つのアノテーションデータを連結\n",
    "2つのDataFrame `transcript_name` と `gene_description` を連結し`gene_products`　という新しいDataFrameを作ります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_products = pd.merge(transcript_name, gene_description, on='gene_id', how='left') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transcript_idのアノテーションが決まればよいので　`how='left'` としました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gene_products.shape)\n",
    "gene_products.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step3. アノテーションデータとカウントデータを連結\n",
    "2つのDataFrame `df` と `gene_products` を連結します。<br>\n",
    "`gene_products` には mRNA のデータしか含まれていないので、rRNA などのデータはこの時点で除かれます。<br>\n",
    "ただし、`gene_name`列の値が `mt-` で始まるミトコンドリア遺伝子が含まれています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_product = df.copy()\n",
    "df_with_product['transcript_id'] = df_with_product.index\n",
    "df_with_product.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_product = pd.merge(df_with_product, gene_products, on='transcript_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatを使った場合\n",
    "# pd.concat([gene_products, df], axis=1, join=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcript_id列をindexにする\n",
    "df_with_product.set_index('transcript_id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "アノテーション付きカウントデータを`count_preprocessed.tsv`として保存します。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# アノテーション付きデータの保存\n",
    "df_with_product.to_csv('output/count_preprocessed.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TPMデータにもアノテーション付与"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tpm_with_product = df_count_tpm.copy()\n",
    "df_tpm_with_product['transcript_id'] = df_tpm_with_product.index\n",
    "df_tpm_with_product = pd.merge(df_tpm_with_product, gene_products, on='transcript_id', how='inner')\n",
    "df_tpm_with_product.set_index('transcript_id', inplace=True)\n",
    "\n",
    "df_tpm_with_product.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# アノテーション付きデータの保存\n",
    "df_tpm_with_product.to_csv('output/tpm_with_product.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 発現変動遺伝子を抽出する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TPM正規化データを用います。<br>\n",
    "wild typeの平均を求めます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_tpm['wt'] = (df_count_tpm['wt_1'] + df_count_tpm['wt_2'] + df_count_tpm['wt_3']) / 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mutantの平均を求めます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_tpm['mutant'] = (df_count_tpm['mutant_1'] + df_count_tpm['mutant_2'] + df_count_tpm['mutant_3']) / 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "発現変動をlog2 fold として求めます。<br>\n",
    "0 での除算を防ぐため、分母に微小な値を加えています。<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_tpm['log2fold'] = df_count_tpm['mutant'] / (df_count_tpm['wt'] + 10**-6)\n",
    "df_count_tpm['log2fold'] = df_count_tpm['log2fold'].apply(np.log2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_tpm.iloc[6085:6090,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "必要部分のみ抜き出し、productと結合します。\n",
    "`df_count_tpm` から'wt', 'mutant', 'log2fold'の列を抜き出し`diff_ex`とします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_ex = df_count_tpm.copy()\n",
    "diff_ex = diff_ex[['wt', 'mutant', 'log2fold']]\n",
    "diff_ex ['transcript_id']= diff_ex.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_ex = pd.merge(diff_ex, gene_products, on = 'transcript_id', how = 'right')\n",
    "diff_ex.set_index('transcript_id', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_ex.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "カウント数が0であるデータを除きます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_ex = diff_ex[diff_ex['wt'] > 0]\n",
    "diff_ex = diff_ex[diff_ex['mutant'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_ex.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_ex.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`diff_ex.sort_values()`を使い`log2fold`の降順に並びかえます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_ex = diff_ex.sort_values(by = 'log2fold',ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "発現変動遺伝子の上位を表示してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutant > wt の上位5番目まで表示\n",
    "diff_ex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wt > mutant の上位5番目まで表示\n",
    "diff_ex.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "102px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "470257d3213e06cc21fd949635d3f77e8207554903083b38e960c3088cc78b2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
